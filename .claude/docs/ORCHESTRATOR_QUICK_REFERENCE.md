# Orchestrator Quick Reference

_Last updated: 2025-10-05_

## How Orchestration Works

**You (the main agent) are the orchestrator.** Specialized agents:
- **Cannot communicate with each other** - they are isolated
- **Return a single report to you** - one message per agent
- **Are stateless** - no memory between launches
- **Don't see other agents' outputs** - unless you pass them context

**Your orchestration responsibilities:**
- Launch agents with specific, detailed task prompts
- Receive and synthesize agent reports
- Pass relevant findings between agents as context
- Decide sequencing, parallelization, and next steps
- Integrate all outputs into a coherent solution

**"Parallel" vs "Sequential" execution:**
- **Parallel**: You launch multiple agents in a single message (they run concurrently but independently)
- **Sequential**: You wait for an agent's report before launching the next one
- Agents never interact directly - you synthesize their outputs

## Quick Start Example

**User request:** "Add authentication to the API"

**Your orchestration flow:**

1. **Launch** python-expert-architect
   - ‚Üí You receive: Design for auth system

2. **Pass design to** python-implementation-specialist
   - ‚Üí You receive: Implementation code

3. **Launch in parallel** (single message):
   - python-code-reviewer
   - type-system-expert
   - ‚Üí You receive: Two separate reports

4. **Synthesize** review findings

5. **Launch** test-development-master with context
   - ‚Üí You receive: Test suite

6. **Integrate** everything and present to user

## Agent Capabilities Matrix

| Agent | Complexity | Primary Use | Parallelization |
|-------|-----------|-------------|-----------------|
| python-code-reviewer | Standard | Code review | ‚úÖ Safe (read-only) |
| code-refactoring-expert | Advanced | Refactoring | ‚ùå Must run alone |
| python-expert-architect | Advanced | Complex patterns, async, frameworks | ‚ö†Ô∏è If separate files |
| python-implementation-specialist | Standard | Standard implementation | ‚ö†Ô∏è If separate files |
| test-development-master | Standard | Testing + TDD + Coverage + Qt | ‚ö†Ô∏è If separate files |
| test-type-safety-specialist | Standard | Type-safe tests | ‚ö†Ô∏è If separate files |
| type-system-expert | Standard | Types + protocols | ‚ö†Ô∏è If separate files |
| qt-ui-modernizer | Advanced | UI/UX + QML + Implementation | ‚ö†Ô∏è If separate files |
| ui-ux-validator | Standard | UI validation from user perspective | ‚úÖ Safe (read-only) |
| qt-concurrency-architect | Advanced | Qt threading | ‚ö†Ô∏è If separate files |
| qt-modelview-painter | Advanced | Model/View + Implementation | ‚ö†Ô∏è If separate files |
| performance-profiler | Standard | Performance analysis | ‚úÖ Safe (read-only) |
| deep-debugger | Advanced | Complex bugs, root cause analysis | ‚úÖ Safe (read-only) |
| threading-debugger | Advanced | Threading bugs, deadlocks, races | ‚úÖ Safe (read-only) |
| venv-keeper | Standard | Environment management | ‚ùå Must run alone |
| api-documentation-specialist | Standard | API design + documentation | ‚úÖ Safe (read-only) |
| **Review Agents (All Read-Only)** | | | |
| agent-consistency-auditor | Standard | Validate metadata, structure, naming | ‚úÖ Always safe |
| documentation-quality-reviewer | Standard | Assess doc completeness, examples | ‚úÖ Always safe |
| cross-reference-validator | Standard | Validate inter-agent references | ‚úÖ Always safe |
| coverage-gap-analyzer | Standard | Identify capability gaps, overlaps | ‚úÖ Always safe |
| best-practices-checker | Standard | Verify modern patterns, security | ‚úÖ Always safe |
| review-synthesis-agent | Standard | Correlate findings, create roadmaps | ‚úÖ Always safe |
| agent-audit-orchestrator | Standard | Orchestrate review agents | ‚úÖ Always safe |

**Legend:**
- ‚úÖ **Safe**: Read-only analysis, always parallelizable
- ‚ö†Ô∏è **Conditional**: Can parallel if file scopes don't overlap
- ‚ùå **Sequential only**: Exclusive access required

## ‚ö†Ô∏è CRITICAL: Parallel Execution Rules

**You can launch agents in parallel ONLY if:**
1. They work on **different files** (non-overlapping scopes)
2. They perform **read-only analysis** (no modifications)
3. They create **different new files** (no naming conflicts)

**Before parallel deployment:**
- ‚úÖ Explicitly define non-overlapping file scopes in prompts
- ‚úÖ Verify both agents won't modify the same files
- ‚úÖ Confirm naming conventions won't conflict
- ‚ùå Never assume agents will "coordinate" - they can't

**What "parallel" actually means:**
- You send a single message with multiple Task tool calls
- Agents execute concurrently but in isolation
- Each returns an independent report to you
- You synthesize findings after all complete

### ‚úÖ SAFE: Parallel Execution Examples

**Different file scopes (non-overlapping):**
- test-development-master: "Create tests for tests/test_auth.py"
- test-type-safety-specialist: "Fix types in tests/test_database.py"

**Read-only analysis (always safe):**
- deep-debugger: "Investigate failures in src/"
- performance-profiler: "Profile application startup"
- python-code-reviewer: "Review code quality in src/api/"

**Different directories:**
- python-implementation-specialist: "Implement features in src/core/"
- test-development-master: "Create tests in tests/integration/"

**All review agents (always safe):**
- agent-consistency-auditor: "Audit all agent definitions"
- documentation-quality-reviewer: "Review documentation"
- best-practices-checker: "Check for anti-patterns"

### ‚ùå UNSAFE: Never Parallel

**Same files - WILL CONFLICT:**
- test-development-master: "Fix all test failures"
- test-type-safety-specialist: "Fix type errors in tests/"

**Same file modifications:**
- python-implementation-specialist: "Update src/config.py"
- test-development-master: "Add test fixtures to src/config.py"

**Overlapping scopes:**
- code-refactoring-expert: "Refactor src/"
- type-system-expert: "Fix types in src/"

**Environment changes during execution:**
- venv-keeper: "Update dependencies"
- Any other agent running simultaneously

## Passing Context Between Agents

Agents are **stateless and isolated**. You must manually pass context:

**‚ùå DON'T** assume agents see each other's work:
1. Launch architect ‚Üí receives design
2. Launch implementation-specialist ‚Üí won't see design

**‚úÖ DO** pass context explicitly:
1. Launch architect ‚Üí receives design
2. Launch implementation-specialist with:
   - "Implement this design: [paste design]"
   - "The architect recommended: [key points]"

**Context passing checklist:**
- [ ] Include relevant prior agent findings in new prompts
- [ ] Summarize multi-agent outputs before next step
- [ ] Reference specific files/functions from earlier reports
- [ ] State what has already been done/found

## Common Orchestration Workflows

### üöÄ New Feature

1. **Launch** python-expert-architect
   - ‚Üí You receive: System design

2. **Pass design to** python-implementation-specialist
   - ‚Üí You receive: Implementation code

3. **Launch in parallel** (single message):
   - python-code-reviewer
   - type-system-expert
   - ‚Üí You receive: Two independent reports

4. **Synthesize findings, then launch** test-development-master
   - ‚Üí You receive: Test suite

5. **Integrate** all outputs and present solution

### üêõ Debug Issue

1. **Launch in parallel** (read-only analysis):
   - deep-debugger
   - threading-debugger (if concurrency suspected)
   - performance-profiler (if performance issue)
   - ‚Üí You receive: Multiple diagnostic reports

2. **Synthesize findings, then launch** python-code-reviewer
   - ‚Üí You receive: Code quality assessment

3. **Pass all context to** python-implementation-specialist
   - ‚Üí You receive: Bug fixes

4. **Launch** test-development-master
   - ‚Üí You receive: Regression tests

### ‚ôªÔ∏è Refactor Code

1. **Launch** python-code-reviewer
   - ‚Üí You receive: Issues and recommendations

2. **Pass findings to** code-refactoring-expert (runs alone)
   - ‚Üí You receive: Refactored code

3. **Launch in parallel**:
   - type-system-expert
   - test-development-master
   - ‚Üí You receive: Type check + test results

### üé® Qt Development

1. **Launch in parallel** (separate file scopes):
   - qt-ui-modernizer ‚Üí "Work on src/ui/main_window.py"
   - qt-modelview-painter ‚Üí "Work on src/models/data_model.py"
   - ‚Üí You receive: Two implementation reports

2. **Launch** ui-ux-validator
   - ‚Üí You receive: UX feedback

3. **Launch** qt-concurrency-architect
   - ‚Üí You receive: Threading review

4. **Launch** test-development-master with all context
   - ‚Üí You receive: Qt tests

### ‚ö° Optimize Performance

1. **Launch** performance-profiler
   - ‚Üí You receive: Bottleneck analysis

2. **Pass findings to** python-expert-architect
   - ‚Üí You receive: Optimization strategy (may include implementation)

3. **If needed, launch** code-refactoring-expert
   - ‚Üí You receive: Optimized code

4. **Launch in parallel**:
   - performance-profiler (verify improvements)
   - test-development-master (ensure correctness)
   - ‚Üí You receive: Performance + test results

### üîç Ecosystem Audit

1. **Launch** agent-audit-orchestrator
   - ‚Üí You receive: Meta-orchestration plan

2. **Launch all review agents in parallel** (single message):
   - agent-consistency-auditor
   - documentation-quality-reviewer
   - cross-reference-validator
   - coverage-gap-analyzer
   - best-practices-checker
   - ‚Üí You receive: Five independent audit reports

3. **Pass all findings to** review-synthesis-agent
   - ‚Üí You receive: Prioritized roadmap

## Agent Selection Guide

### When to Use Which Implementation Agent?

**python-expert-architect** (Advanced complexity):
- Async/await, asyncio, concurrent.futures patterns
- Decorators, metaclasses, descriptors, protocols
- Plugin systems, framework architecture
- Complex state machines or concurrency
- Performance-critical algorithms with tradeoffs

**python-implementation-specialist** (Standard tasks):
- CRUD operations, REST endpoints
- Data validation, parsing, transformation
- File I/O, configuration loading
- Utility functions, helpers
- Straightforward business logic

**Rule of thumb**: If you need to explain complex tradeoffs or design patterns ‚Üí architect. If requirements are clear and straightforward ‚Üí specialist.

### When to Use Which Test Agent?

**test-development-master**:
- Creating new test suites from scratch
- Coverage analysis and gap filling
- TDD workflow guidance
- Qt widget testing
- Integration and end-to-end tests

**test-type-safety-specialist**:
- Fixing type errors in existing tests
- Type-safe mock and fixture design
- Generic test utilities with proper typing
- Reviewing type ignore comments in tests

**Together (separate scopes)**:
- test-development-master ‚Üí "Create tests for src/services/"
- test-type-safety-specialist ‚Üí "Fix types in tests/test_models.py"

## MCP Tools Usage

You have access to specialized MCP tools:

**sequential-thinking**:
- Complex multi-step reasoning
- Analyzing tradeoffs before agent deployment
- Planning orchestration strategies

**context7** (library docs):
- Fetching current library documentation
- Validating API usage before implementation
- Passing up-to-date examples to agents

**serena** (code navigation):
- Smart symbolic code analysis
- Finding symbols without reading full files
- Understanding codebase structure before agent deployment
- Token-efficient code exploration

**Typical usage pattern:**

1. **Use serena tools** to understand codebase structure
2. **Use sequential-thinking** to plan orchestration strategy
3. **Use context7** to fetch current library documentation
4. **Launch specialized agents** with gathered context

## Pre-Deployment Checklist

Before launching agents, verify:

**1. File Scope Check:**
- [ ] Will agents modify different files? ‚Üí Safe to parallel
- [ ] Will agents modify same files? ‚Üí Must run sequentially
- [ ] Are file scopes explicitly defined in prompts?

**2. Operation Type Check:**
- [ ] Read-only analysis? ‚Üí Safe to parallel (always)
- [ ] Both creating new files? ‚Üí Check naming conflicts
- [ ] Both modifying code? ‚Üí Verify zero overlap

**3. Context Passing Check:**
- [ ] Does agent need prior findings? ‚Üí Include in prompt
- [ ] Is task self-contained? ‚Üí Can launch independently
- [ ] Will next agent need these results? ‚Üí Wait for completion

**4. Resource Check:**
- [ ] Heavy computation? ‚Üí Consider limits, don't over-parallelize
- [ ] File system intensive? ‚Üí May benefit from sequencing
- [ ] Many parallel agents? ‚Üí Group in batches

## Quick Decision Rules

- **One file, multiple agents?** ‚Üí Queue sequentially, pass context between
- **Implementation complete?** ‚Üí Launch analysis team in parallel
- **Qt GUI work?** ‚Üí Assign separate files to each agent explicitly
- **Unknown bug?** ‚Üí Launch debug team in parallel (all read-only)
- **Need refactoring?** ‚Üí Solo code-refactoring-expert (runs alone)
- **Uncertain about overlap?** ‚Üí Default to sequential execution
- **Need ecosystem audit?** ‚Üí Launch all review agents in parallel
- **Quality check?** ‚Üí Launch review team in parallel (always safe)

## Red Flags (Don't Do This)

‚ùå **Launching agents without explicit file scopes** ‚Üí Leads to overlaps
‚ùå **Assuming agents will coordinate** ‚Üí They can't see each other
‚ùå **Not passing context between sequential agents** ‚Üí Agents start from scratch
‚ùå **Launching tests while code is being modified** ‚Üí Inconsistent results
‚ùå **Running venv-keeper with other agents** ‚Üí Environment conflicts
‚ùå **Refactoring without review first** ‚Üí May break working code
‚ùå **Using python-expert-architect for simple tasks** ‚Üí Unnecessary complexity
‚ùå **Using python-implementation-specialist for advanced patterns** ‚Üí Insufficient
‚ùå **Forgetting to synthesize multi-agent outputs** ‚Üí Conflicting recommendations

‚úÖ **Review agents can ALWAYS run in parallel** ‚Üí All read-only, always safe
‚úÖ **Pass previous findings to next agent** ‚Üí Better results
‚úÖ **Define explicit non-overlapping scopes** ‚Üí Safe parallel execution

## Agent Interaction Patterns

### Pattern: Sequential with Context Passing

1. **Launch** architect
   - ‚Üí You receive: Design

2. **Synthesize design, then launch** implementation with context
   - ‚Üí You receive: Implementation code

3. **Launch in parallel**: reviewer + type-checker
   - ‚Üí You receive: Two independent reports

4. **Synthesize** findings and present to user

### Pattern: Parallel Analysis

1. **Launch in parallel**: debugger + profiler + reviewer
   - ‚Üí You receive: Multiple independent reports

2. **Synthesize** all findings and identify root cause

3. **Launch** implementation with synthesized context
   - ‚Üí You receive: Bug fix

### Pattern: Divide and Conquer

1. **Split task** into non-overlapping file scopes

2. **Launch in parallel**:
   - specialist1 for scope1
   - specialist2 for scope2
   - ‚Üí You receive: Two independent implementations

3. **Launch in parallel**:
   - test-master for scope1
   - test-safety for scope2
   - ‚Üí You receive: Two test results

4. **Integrate** all outputs

## Output Priority Levels

When synthesizing multi-agent findings:

1. üî¥ **Critical**: Crashes, data loss, security vulnerabilities
2. üü° **Important**: Performance issues, major bugs, broken functionality
3. üü¢ **Improvements**: Code quality, refactoring opportunities, optimizations
4. üîµ **Enhancements**: Modernization, nice-to-haves, style improvements

## Escalation Triggers

When orchestrating, escalate to user if:

- **Agent fails twice** ‚Üí Ask user for guidance or alternative approach
- **Conflicting agent recommendations** ‚Üí Present options with your synthesis
- **Missing capabilities** ‚Üí Suggest manual intervention or tool limitations
- **Scope ambiguity** ‚Üí Request clarification before parallel deployment
- **Complex tradeoffs** ‚Üí Present analysis and ask for user preference

## Cross-References

Related documentation:
- **AGENT_STANDARDS.md**: Agent design patterns and conventions
- **ORCHESTRATION.md**: Detailed orchestration strategies and patterns
- Individual agent `.md` files: Specific agent capabilities and usage

---

**Remember**: You are the orchestrator. Agents are tools you deploy, not collaborators. Your job is to plan, launch, synthesize, and integrate their independent outputs into cohesive solutions.
