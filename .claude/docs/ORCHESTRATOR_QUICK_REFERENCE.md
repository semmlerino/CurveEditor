# Orchestrator Quick Reference

_Last updated: 2025-10-05_

## How Orchestration Works

**You (the main agent) are the orchestrator.** Specialized agents:
- **Cannot communicate with each other** - they are isolated
- **Return a single report to you** - one message per agent
- **Are stateless** - no memory between launches
- **Don't see other agents' outputs** - unless you pass them context

**Your orchestration responsibilities:**
- Launch agents with specific, detailed task prompts
- Receive and synthesize agent reports
- Pass relevant findings between agents as context
- Decide sequencing, parallelization, and next steps
- Integrate all outputs into a coherent solution

**"Parallel" vs "Sequential" execution:**
- **Parallel**: You launch multiple agents in a single message (they run concurrently but independently)
- **Sequential**: You wait for an agent's report before launching the next one
- Agents never interact directly - you synthesize their outputs

## Quick Start Example

**User request:** "Add authentication to the API"

**Your orchestration flow:**

1. **Launch** python-expert-architect
   - â†’ You receive: Design for auth system

2. **Pass design to** python-implementation-specialist
   - â†’ You receive: Implementation code

3. **Launch in parallel** (single message):
   - python-code-reviewer
   - type-system-expert
   - â†’ You receive: Two separate reports

4. **Synthesize** review findings

5. **Launch** test-development-master with context
   - â†’ You receive: Test suite

6. **Integrate** everything and present to user

## Agent Capabilities Matrix

| Agent | Complexity | Primary Use | Parallelization |
|-------|-----------|-------------|-----------------|
| python-code-reviewer | Standard | Code review | âœ… Safe (read-only) |
| code-refactoring-expert | Advanced | Refactoring | âŒ Must run alone |
| python-expert-architect | Advanced | Complex patterns, async, frameworks | âš ï¸ If separate files |
| python-implementation-specialist | Standard | Standard implementation | âš ï¸ If separate files |
| test-development-master | Standard | Testing + TDD + Coverage + Qt | âš ï¸ If separate files |
| test-type-safety-specialist | Standard | Type-safe tests | âš ï¸ If separate files |
| type-system-expert | Standard | Types + protocols | âš ï¸ If separate files |
| qt-ui-modernizer | Advanced | UI/UX + QML + Implementation | âš ï¸ If separate files |
| ui-ux-validator | Standard | UI validation from user perspective | âœ… Safe (read-only) |
| qt-concurrency-architect | Advanced | Qt threading | âš ï¸ If separate files |
| qt-modelview-painter | Advanced | Model/View + Implementation | âš ï¸ If separate files |
| performance-profiler | Standard | Performance analysis | âœ… Safe (read-only) |
| deep-debugger | Advanced | Complex bugs, root cause analysis | âœ… Safe (read-only) |
| threading-debugger | Advanced | Threading bugs, deadlocks, races | âœ… Safe (read-only) |
| venv-keeper | Standard | Environment management | âŒ Must run alone |
| api-documentation-specialist | Standard | API design + documentation | âœ… Safe (read-only) |
| **Review Agents (All Read-Only)** | | | |
| agent-consistency-auditor | Standard | Validate metadata, structure, naming | âœ… Always safe |
| documentation-quality-reviewer | Standard | Assess doc completeness, examples | âœ… Always safe |
| cross-reference-validator | Standard | Validate inter-agent references | âœ… Always safe |
| coverage-gap-analyzer | Standard | Identify capability gaps, overlaps | âœ… Always safe |
| best-practices-checker | Standard | Verify modern patterns, security | âœ… Always safe |
| review-synthesis-agent | Standard | Correlate findings, create roadmaps | âœ… Always safe |
| agent-audit-orchestrator | Standard | Orchestrate review agents | âœ… Always safe |

**Legend:**
- âœ… **Safe**: Read-only analysis, always parallelizable
- âš ï¸ **Conditional**: Can parallel if file scopes don't overlap
- âŒ **Sequential only**: Exclusive access required

## âš ï¸ CRITICAL: Parallel Execution Rules

**You can launch agents in parallel ONLY if:**
1. They work on **different files** (non-overlapping scopes)
2. They perform **read-only analysis** (no modifications)
3. They create **different new files** (no naming conflicts)

**Before parallel deployment:**
- âœ… Explicitly define non-overlapping file scopes in prompts
- âœ… Verify both agents won't modify the same files
- âœ… Confirm naming conventions won't conflict
- âŒ Never assume agents will "coordinate" - they can't

**What "parallel" actually means:**
- You send a single message with multiple Task tool calls
- Agents execute concurrently but in isolation
- Each returns an independent report to you
- You synthesize findings after all complete

### âœ… SAFE: Parallel Execution Examples

**Different file scopes (non-overlapping):**
- test-development-master: "Create tests for tests/test_auth.py"
- test-type-safety-specialist: "Fix types in tests/test_database.py"

**Read-only analysis (always safe):**
- deep-debugger: "Investigate failures in src/"
- performance-profiler: "Profile application startup"
- python-code-reviewer: "Review code quality in src/api/"

**Different directories:**
- python-implementation-specialist: "Implement features in src/core/"
- test-development-master: "Create tests in tests/integration/"

**All review agents (always safe):**
- agent-consistency-auditor: "Audit all agent definitions"
- documentation-quality-reviewer: "Review documentation"
- best-practices-checker: "Check for anti-patterns"

### âŒ UNSAFE: Never Parallel

**Same files - WILL CONFLICT:**
- test-development-master: "Fix all test failures"
- test-type-safety-specialist: "Fix type errors in tests/"

**Same file modifications:**
- python-implementation-specialist: "Update src/config.py"
- test-development-master: "Add test fixtures to src/config.py"

**Overlapping scopes:**
- code-refactoring-expert: "Refactor src/"
- type-system-expert: "Fix types in src/"

**Environment changes during execution:**
- venv-keeper: "Update dependencies"
- Any other agent running simultaneously

## Passing Context Between Agents

Agents are **stateless and isolated**. You must manually pass context:

**âŒ DON'T** assume agents see each other's work:
1. Launch architect â†’ receives design
2. Launch implementation-specialist â†’ won't see design

**âœ… DO** pass context explicitly:
1. Launch architect â†’ receives design
2. Launch implementation-specialist with:
   - "Implement this design: [paste design]"
   - "The architect recommended: [key points]"

**Context passing checklist:**
- [ ] Include relevant prior agent findings in new prompts
- [ ] Summarize multi-agent outputs before next step
- [ ] Reference specific files/functions from earlier reports
- [ ] State what has already been done/found

## Common Orchestration Workflows

### ğŸš€ New Feature

1. **Launch** python-expert-architect
   - â†’ You receive: System design

2. **Pass design to** python-implementation-specialist
   - â†’ You receive: Implementation code

3. **Launch in parallel** (single message):
   - python-code-reviewer
   - type-system-expert
   - â†’ You receive: Two independent reports

4. **Synthesize findings, then launch** test-development-master
   - â†’ You receive: Test suite

5. **Integrate** all outputs and present solution

### ğŸ› Debug Issue

1. **Launch in parallel** (read-only analysis):
   - deep-debugger
   - threading-debugger (if concurrency suspected)
   - performance-profiler (if performance issue)
   - â†’ You receive: Multiple diagnostic reports

2. **Synthesize findings, then launch** python-code-reviewer
   - â†’ You receive: Code quality assessment

3. **Pass all context to** python-implementation-specialist
   - â†’ You receive: Bug fixes

4. **Launch** test-development-master
   - â†’ You receive: Regression tests

### â™»ï¸ Refactor Code

1. **Launch** python-code-reviewer
   - â†’ You receive: Issues and recommendations

2. **Pass findings to** code-refactoring-expert (runs alone)
   - â†’ You receive: Refactored code

3. **Launch in parallel**:
   - type-system-expert
   - test-development-master
   - â†’ You receive: Type check + test results

### ğŸ¨ Qt Development

1. **Launch in parallel** (separate file scopes):
   - qt-ui-modernizer â†’ "Work on src/ui/main_window.py"
   - qt-modelview-painter â†’ "Work on src/models/data_model.py"
   - â†’ You receive: Two implementation reports

2. **Launch** ui-ux-validator
   - â†’ You receive: UX feedback

3. **Launch** qt-concurrency-architect
   - â†’ You receive: Threading review

4. **Launch** test-development-master with all context
   - â†’ You receive: Qt tests

### âš¡ Optimize Performance

1. **Launch** performance-profiler
   - â†’ You receive: Bottleneck analysis

2. **Pass findings to** python-expert-architect
   - â†’ You receive: Optimization strategy (may include implementation)

3. **If needed, launch** code-refactoring-expert
   - â†’ You receive: Optimized code

4. **Launch in parallel**:
   - performance-profiler (verify improvements)
   - test-development-master (ensure correctness)
   - â†’ You receive: Performance + test results

### ğŸ” Ecosystem Audit

1. **Launch** agent-audit-orchestrator
   - â†’ You receive: Meta-orchestration plan

2. **Launch all review agents in parallel** (single message):
   - agent-consistency-auditor
   - documentation-quality-reviewer
   - cross-reference-validator
   - coverage-gap-analyzer
   - best-practices-checker
   - â†’ You receive: Five independent audit reports

3. **Pass all findings to** review-synthesis-agent
   - â†’ You receive: Prioritized roadmap

## Agent Selection Guide

### When to Use Which Implementation Agent?

**python-expert-architect** (Advanced complexity):
- Async/await, asyncio, concurrent.futures patterns
- Decorators, metaclasses, descriptors, protocols
- Plugin systems, framework architecture
- Complex state machines or concurrency
- Performance-critical algorithms with tradeoffs

**python-implementation-specialist** (Standard tasks):
- CRUD operations, REST endpoints
- Data validation, parsing, transformation
- File I/O, configuration loading
- Utility functions, helpers
- Straightforward business logic

**Rule of thumb**: If you need to explain complex tradeoffs or design patterns â†’ architect. If requirements are clear and straightforward â†’ specialist.

### When to Use Which Test Agent?

**test-development-master**:
- Creating new test suites from scratch
- Coverage analysis and gap filling
- TDD workflow guidance
- Qt widget testing
- Integration and end-to-end tests

**test-type-safety-specialist**:
- Fixing type errors in existing tests
- Type-safe mock and fixture design
- Generic test utilities with proper typing
- Reviewing type ignore comments in tests

**Together (separate scopes)**:
- test-development-master â†’ "Create tests for src/services/"
- test-type-safety-specialist â†’ "Fix types in tests/test_models.py"

## MCP Tools Usage

You have access to specialized MCP tools:

**sequential-thinking**:
- Complex multi-step reasoning
- Analyzing tradeoffs before agent deployment
- Planning orchestration strategies

**context7** (library docs):
- Fetching current library documentation
- Validating API usage before implementation
- Passing up-to-date examples to agents

**serena** (code navigation):
- Smart symbolic code analysis
- Finding symbols without reading full files
- Understanding codebase structure before agent deployment
- Token-efficient code exploration

**Typical usage pattern:**

1. **Use serena tools** to understand codebase structure
2. **Use sequential-thinking** to plan orchestration strategy
3. **Use context7** to fetch current library documentation
4. **Launch specialized agents** with gathered context

## Pre-Deployment Checklist

Before launching agents, verify:

**1. File Scope Check:**
- [ ] Will agents modify different files? â†’ Safe to parallel
- [ ] Will agents modify same files? â†’ Must run sequentially
- [ ] Are file scopes explicitly defined in prompts?

**2. Operation Type Check:**
- [ ] Read-only analysis? â†’ Safe to parallel (always)
- [ ] Both creating new files? â†’ Check naming conflicts
- [ ] Both modifying code? â†’ Verify zero overlap

**3. Context Passing Check:**
- [ ] Does agent need prior findings? â†’ Include in prompt
- [ ] Is task self-contained? â†’ Can launch independently
- [ ] Will next agent need these results? â†’ Wait for completion

**4. Resource Check:**
- [ ] Heavy computation? â†’ Consider limits, don't over-parallelize
- [ ] File system intensive? â†’ May benefit from sequencing
- [ ] Many parallel agents? â†’ Group in batches

## Quick Decision Rules

- **One file, multiple agents?** â†’ Queue sequentially, pass context between
- **Implementation complete?** â†’ Launch analysis team in parallel
- **Qt GUI work?** â†’ Assign separate files to each agent explicitly
- **Unknown bug?** â†’ Launch debug team in parallel (all read-only)
- **Need refactoring?** â†’ Solo code-refactoring-expert (runs alone)
- **Uncertain about overlap?** â†’ Default to sequential execution
- **Need ecosystem audit?** â†’ Launch all review agents in parallel
- **Quality check?** â†’ Launch review team in parallel (always safe)

## Red Flags (Don't Do This)

âŒ **Launching agents without explicit file scopes** â†’ Leads to overlaps
âŒ **Assuming agents will coordinate** â†’ They can't see each other
âŒ **Not passing context between sequential agents** â†’ Agents start from scratch
âŒ **Launching tests while code is being modified** â†’ Inconsistent results
âŒ **Running venv-keeper with other agents** â†’ Environment conflicts
âŒ **Refactoring without review first** â†’ May break working code
âŒ **Using python-expert-architect for simple tasks** â†’ Unnecessary complexity
âŒ **Using python-implementation-specialist for advanced patterns** â†’ Insufficient
âŒ **Forgetting to synthesize multi-agent outputs** â†’ Conflicting recommendations

âœ… **Review agents can ALWAYS run in parallel** â†’ All read-only, always safe
âœ… **Pass previous findings to next agent** â†’ Better results
âœ… **Define explicit non-overlapping scopes** â†’ Safe parallel execution

## Agent Interaction Patterns

### Pattern: Sequential with Context Passing

1. **Launch** architect
   - â†’ You receive: Design

2. **Synthesize design, then launch** implementation with context
   - â†’ You receive: Implementation code

3. **Launch in parallel**: reviewer + type-checker
   - â†’ You receive: Two independent reports

4. **Synthesize** findings and present to user

### Pattern: Parallel Analysis

1. **Launch in parallel**: debugger + profiler + reviewer
   - â†’ You receive: Multiple independent reports

2. **Synthesize** all findings and identify root cause

3. **Launch** implementation with synthesized context
   - â†’ You receive: Bug fix

### Pattern: Divide and Conquer

1. **Split task** into non-overlapping file scopes

2. **Launch in parallel**:
   - specialist1 for scope1
   - specialist2 for scope2
   - â†’ You receive: Two independent implementations

3. **Launch in parallel**:
   - test-master for scope1
   - test-safety for scope2
   - â†’ You receive: Two test results

4. **Integrate** all outputs

## Output Priority Levels

When synthesizing multi-agent findings:

1. ğŸ”´ **Critical**: Crashes, data loss, security vulnerabilities
2. ğŸŸ¡ **Important**: Performance issues, major bugs, broken functionality
3. ğŸŸ¢ **Improvements**: Code quality, refactoring opportunities, optimizations
4. ğŸ”µ **Enhancements**: Modernization, nice-to-haves, style improvements

## Escalation Triggers

When orchestrating, escalate to user if:

- **Agent fails twice** â†’ Ask user for guidance or alternative approach
- **Conflicting agent recommendations** â†’ Present options with your synthesis
- **Missing capabilities** â†’ Suggest manual intervention or tool limitations
- **Scope ambiguity** â†’ Request clarification before parallel deployment
- **Complex tradeoffs** â†’ Present analysis and ask for user preference

## Cross-References

Related documentation:
- **AGENT_STANDARDS.md**: Agent design patterns and conventions
- **ORCHESTRATION.md**: Detailed orchestration strategies and patterns
- Individual agent `.md` files: Specific agent capabilities and usage

---

**Remember**: You are the orchestrator. Agents are tools you deploy, not collaborators. Your job is to plan, launch, synthesize, and integrate their independent outputs into cohesive solutions.
